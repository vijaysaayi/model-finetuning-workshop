{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a67df9",
   "metadata": {},
   "source": [
    "# Fine-Tuning Workshop: Training a Custom AI Assistant for Axiomcart\n",
    "\n",
    "In this workshop, we'll learn how to fine-tune a language model to create a custom AI assistant for customer support. We'll be using the Qwen2-0.5B model and fine-tuning it with LoRA (Low-Rank Adaptation) to answer Axiomcart-specific questions.\n",
    "\n",
    "## What you'll learn:\n",
    "- How to load and use a pre-trained language model\n",
    "- How to prepare training data for fine-tuning\n",
    "- How to implement LoRA for efficient fine-tuning\n",
    "- How to compare base model vs fine-tuned model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c39c6c",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for our fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de398fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "q:\\Experiments\\workshop-notebook\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Ensure CPU usage (you can change this to \"cuda\" if you have a GPU)\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e73567",
   "metadata": {},
   "source": [
    "## Step 2: Load the Base Model and Tokenizer\n",
    "\n",
    "We'll use the Qwen2-0.5B model, which is a compact yet powerful language model suitable for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3740e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Qwen/Qwen2-0.5B\n",
      "Model loaded successfully!\n",
      "Model parameters: 494,032,768\n"
     ]
    }
   ],
   "source": [
    "# Load the Qwen 0.5B model and tokenizer\n",
    "model_name = \"Qwen/Qwen2-0.5B\"\n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\").to(device)\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Model parameters: {base_model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0fd6f5",
   "metadata": {},
   "source": [
    "## Step 3: Test Base Model Performance\n",
    "\n",
    "Before fine-tuning, let's see how the base model performs on our Axiomcart-specific questions. This will help us understand the improvement after fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde33404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Can I use MasterCard for payment?\n",
      "Response: Yes, MasterCard is accepted as a payment method by Axiomcart. However, Axiomcart strongly recommends using credit cards for orders over $50, and it's important to note that it is not the preferred method for customers who are less inclined towards using credit cards.\n",
      "--------------------------------------------------------------------------------\n",
      "Question: How do I return an item?\n",
      "Response: Axiomcart provides a return policy that allows customers to return items within 30 days of purchase or any time after the 30 days. The company ensures that the items are returned in good condition and in accordance with the terms and conditions of the return policy.\n",
      "\n",
      "                    If you have any questions or concerns regarding the return policy, please feel free to contact our customer support team by email at support@axiomcart.com or by phone at +1 555 555 5555. Our customer support team is dedicated to providing exceptional customer service and will work with you to ensure a successful and hassle-free return process.\n",
      "\n",
      "                    Thank you for choosing Axiomcart. We look forward to welcoming you back on our platform with renewed confidence and satisfaction.\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Do you ship internationally?\n",
      "Response: Our shipping options are extensive, and we\n",
      "--------------------------------------------------------------------------------\n",
      "Question: Is there a discount for new customers?\n",
      "Response: <p>Yes, it's possible to get the discount even if you're not a new customer. You can use the promotional code FIRST10 to avail of the discount. Simply select FIRST10 during checkout to get your discount.</p>\n",
      "\n",
      "    **DISCOUNT PRICING:**\n",
      "\n",
      "    **First Time Customer Discount:**\n",
      "    - 10% discount on first purchase.\n",
      "\n",
      "    **Customer Care:**\n",
      "    - Our dedicated customer support team is always ready to assist you with any questions or concerns you may have.\n",
      "\n",
      "    **Customer Support:**\n",
      "    - Our customer support team is available to assist you through multiple channels, including direct\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "KNOWLEDGE_BASE = \"\"\"\n",
    "    **COMPANY KNOWLEDGE BASE:**\n",
    "\n",
    "    **Account Management:**\n",
    "    - Account Creation: Customers can create accounts by navigating to our comprehensive sign-up page where they will need to carefully fill in all their personal details including their full name, valid email address, and a secure password that meets our security requirements. After completing the registration form and submitting all required information, customers must verify their email address by clicking the verification link sent to their email inbox to fully activate their account and gain access to all platform features.\n",
    "\n",
    "    **Payment Methods:**\n",
    "    - Accepted payments: Axiomcart proudly accepts a wide variety of payment methods to ensure maximum convenience for our valued customers, including all major credit cards such as Visa, MasterCard, and American Express, as well as popular digital payment solutions like PayPal, and traditional bank transfer options for those who prefer direct banking transactions.\n",
    "\n",
    "    **Order Management:**\n",
    "    - Order Tracking: Once your order has been carefully processed by our fulfillment team and handed over to our trusted shipping partners, you will automatically receive a detailed tracking number via email notification. This tracking number can be used to monitor your package's journey in real-time either through our comprehensive order tracking system on our website or by visiting the carrier's official tracking portal for the most up-to-date delivery information.\n",
    "    - Order Changes/Cancellations: Customers have the flexibility to cancel or modify their orders within a 24-hour window from the time of initial placement, provided that the order has not yet been processed by our fulfillment center and moved to the shipping preparation stage. Once an order has entered the processing phase, customers will need to contact our dedicated customer service team who will do their best to accommodate any changes or cancellation requests.\n",
    "\n",
    "    **Returns & Exchanges:**\n",
    "    - Return Policy: Axiomcart maintains a customer-friendly 30-day return policy that allows customers to return items that are in their original, unused condition with all original tags and packaging intact. To initiate a return, customers must first contact our customer service team to obtain proper return authorization and receive detailed instructions on the return process.\n",
    "\n",
    "    **Security & Privacy:**\n",
    "    - Data Protection: At Axiomcart, we take your privacy and data security extremely seriously. We employ industry-standard encryption technologies and robust security protocols to safeguard all personal information provided by our customers. We maintain strict policies regarding data sharing and absolutely do not share, sell, or distribute customer data to any third parties without explicit customer consent, except where required by law.\n",
    "\n",
    "    **Shipping:**\n",
    "    - International Shipping: Axiomcart is proud to offer comprehensive international shipping services to customers in over 50 countries worldwide. Please note that shipping rates, delivery timeframes, and available shipping options may vary significantly depending on your specific geographic location, local customs requirements, and the size and weight of your order.\n",
    "\n",
    "    **Customer Support:**\n",
    "    - Contact Methods: Our dedicated customer support team is available to assist you through multiple convenient channels including direct email communication at support@axiomcart.com, or through our real-time live chat feature readily accessible on our website for immediate assistance.\n",
    "    - Issue Resolution: If you encounter any problems or concerns regarding your order, please don't hesitate to contact our customer service team with your complete order number and a detailed description of the issue you're experiencing. Our trained representatives will work diligently to investigate and resolve your concern promptly.\n",
    "\n",
    "    **Promotions:**\n",
    "    - First-time Customer Discount: As a special welcome offer for new customers joining the Axiomcart family, we are pleased to provide an exclusive 10% discount on your very first purchase. Simply use the promotional code 'FIRST10' during checkout to take advantage of this limited-time offer.\n",
    "\"\"\"\n",
    "\n",
    "# Test with multiple questions\n",
    "test_questions = [\n",
    "    \"Can I use MasterCard for payment?\",\n",
    "    \"How do I return an item?\",\n",
    "    \"Do you ship internationally?\",\n",
    "    \"Is there a discount for new customers?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    input_text = f\"\"\"                    \n",
    "                    SystemPrompt: \n",
    "                        You are a helpful and professional customer service AI assistant for Axiomcart, an e-commerce platform. \n",
    "                        Your role is to provide comprehensive, detailed, and thorough responses to customer inquiries based on the company's policies and procedures. \n",
    "                        You are very spontaneous and humorous, always maintaining a friendly and professional tone. \n",
    "                        You provide concise and accurate answers, ensuring that customers feel valued and understood.\n",
    "\n",
    "                        {KNOWLEDGE_BASE}\n",
    "\n",
    "                    UserQuery:\n",
    "                        {question}\n",
    "\n",
    "                    Response:\n",
    "                  \"\"\"\n",
    "    \n",
    "    # Tokenize and generate response\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = base_model.generate(\n",
    "            **inputs, \n",
    "            temperature=0.7,\n",
    "            max_new_tokens=200,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract the response part\n",
    "    response = response.split(\"Response:\")[-1].strip()\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e225408",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Training Data\n",
    "\n",
    "Let's create a dataset of FAQ questions and answers specific to Axiomcart. This will be used to train our model to respond like a customer support assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fa388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Enhanced Dataset Statistics:\n",
      "- Training dataset: 13 examples\n",
      "- Evaluation dataset: 4 examples\n",
      "- Total: 17 examples\n",
      "- Coverage: Account Management, Payments, Orders, Returns, Support, Shipping, Promotions, Security, Products\n",
      "\n",
      "ğŸ” Sample training data point:\n",
      "Instruction: What is your return policy?\n",
      "Response: Got buyer's remorse? Hey, it happens to the best of us - even Napoleon probably regretted a few purc...\n",
      "\n",
      "ğŸ§ª Sample evaluation data point:\n",
      "Instruction: How can I track my order?\n",
      "Response: Ah, the eternal question - 'Where's my stuff?!' ğŸ“¦ Don't worry, we've got you covered like a detectiv...\n"
     ]
    }
   ],
   "source": [
    "# Enhanced FAQ data for Axiomcart with more variety and scenarios\n",
    "# Enhanced FAQ data for Axiomcart - Concise version (2 lines, <150 words)\n",
    "faq_data = [\n",
    "    # Account Management\n",
    "    {\"instruction\": \"How do I create an account on Axiomcart?\", \"response\": \"Creating an account is super easy! ğŸ‰ Navigate to our sign-up page, fill in your details (name, email, secure password), then verify your email. Click the verification link we send you and voilÃ  - welcome to the Axiomcart family! ğŸš€\"},\n",
    "    \n",
    "    {\"instruction\": \"I forgot my password, how can I reset it?\", \"response\": \"Happens to the best of us! ğŸ¤¦â€â™€ï¸ Just click 'Forgot Password' on our login page and we'll email you reset instructions. Follow the link to create a new secure password - maybe avoid 'password123' this time! ğŸ˜‰ğŸ”\"},\n",
    "    \n",
    "    # Payment Methods\n",
    "    {\"instruction\": \"What payment methods does Axiomcart accept?\", \"response\": \"We're the Swiss Army knife of payments! ğŸ’³ We accept all major credit cards (Visa, MasterCard, American Express), PayPal, and bank transfers. Basically, we've got more payment options than a food court has restaurants! ğŸ•ğŸ’°\"},\n",
    "    \n",
    "    {\"instruction\": \"Is it safe to save my credit card information?\", \"response\": \"Absolutely! Your payment info is locked up tighter than Fort Knox! ğŸ° We use industry-leading encryption and PCI DSS compliance standards - like having a digital bodyguard for your financial info. We take security more seriously than a sommelier takes wine! ğŸ·ğŸ›¡ï¸\"},\n",
    "    \n",
    "    # Order Management\n",
    "    {\"instruction\": \"How can I track my order?\", \"response\": \"The eternal 'where's my stuff?' question! ğŸ“¦ Once processed, you'll get a tracking number via email automatically. Use it on our website or the carrier's portal to follow your package's journey - it's like GPS for goodies! ğŸ—ºï¸âœ¨\"},\n",
    "    \n",
    "    {\"instruction\": \"How long does shipping usually take?\", \"response\": \"We're faster than your morning coffee delivery! â° Domestic orders: 3-5 days standard, 1-2 days express. International shipping takes 7-14 days depending on location and customs - time for your package to collect passport stamps! ğŸŒâœˆï¸\"},\n",
    "    \n",
    "    {\"instruction\": \"Can I change or cancel my order after placing it?\", \"response\": \"Changed your mind? We totally get it! ğŸ­ You have 24 hours to modify or cancel, unless it's already processing. After that, contact our customer service team - we're basically order-modification wizards! ğŸª„âš¡\"},\n",
    "    \n",
    "    # Returns & Refunds\n",
    "    {\"instruction\": \"What is your return policy?\", \"response\": \"Got buyer's remorse? It happens! ğŸ˜… We offer a 30-day return policy for items in original condition with tags. Contact customer service for return authorization and step-by-step instructions - we won't judge your shopping decisions! ğŸ›ï¸ğŸ’­\"},\n",
    "    \n",
    "    {\"instruction\": \"How do I return a defective item?\", \"response\": \"A defective item is totally unacceptable! ğŸ˜¤ Contact our customer service immediately with your order number and photos. We'll arrange free return shipping and send a replacement or refund - defective items get VIP treatment! ğŸ“¦âœ¨\"},\n",
    "    \n",
    "    # Customer Support\n",
    "    {\"instruction\": \"How can I contact customer support?\", \"response\": \"We're easier to reach than your favorite pizza place! ğŸ“ğŸ• Email us at support@axiomcart.com or use our live chat on the website. We're standing by like customer service superheroes, coffee in hand, ready to help! â˜•ğŸ¦¸â€â™€ï¸\"},\n",
    "    \n",
    "    {\"instruction\": \"What are your customer service hours?\", \"response\": \"We're practically nocturnal! ğŸ¦‰ Live chat and email support are 24/7 because questions don't follow schedules. Phone support: Monday-Friday 8 AM-8 PM EST, weekends 10 AM-6 PM EST. We're here more than your favorite coffee shop! â˜•â°\"},\n",
    "    \n",
    "    # Shipping & International\n",
    "    {\"instruction\": \"Does Axiomcart ship internationally?\", \"response\": \"Around the world in 50+ countries! ğŸŒâœˆï¸ We offer comprehensive international shipping because awesome products deserve to see the world. Rates and timeframes vary by location - we haven't figured out teleportation yet! ğŸš€ğŸ“¦\"},\n",
    "    \n",
    "    {\"instruction\": \"Do I have to pay customs fees for international orders?\", \"response\": \"Ah, the customs question! ğŸ›ƒ Sometimes your country charges duties and taxes - think of it as your package's entry fee. These fees are determined by your local customs authority and are the customer's responsibility - international shopping's adventure tax! ğŸŒğŸ’°\"},\n",
    "    \n",
    "    # Promotions & Discounts\n",
    "    {\"instruction\": \"Are there any discounts for first-time customers?\", \"response\": \"Welcome to the party! ğŸ‰ New customers get an exclusive 10% discount on their first purchase. Just use code 'FIRST10' at checkout - it's like a secret handshake for savings! ğŸ’°âœ¨\"},\n",
    "    \n",
    "    {\"instruction\": \"Do you have a loyalty program?\", \"response\": \"You bet! ğŸŒŸ Earn points with every purchase, redeem for discounts, get early sale access and birthday surprises. The more you shop, the more perks you unlock - like leveling up in a game with useful rewards! ğŸ®ğŸ\"},\n",
    "    \n",
    "    # Security & Privacy\n",
    "    {\"instruction\": \"How secure is my personal information on Axiomcart?\", \"response\": \"Your data is more secure than the Crown Jewels! ğŸ‘‘ğŸ” We use industry-standard encryption and strict privacy policies. We don't share, sell, or distribute your data to third parties without consent - your secrets are safe with us! ğŸ¤âœ¨\"},\n",
    "    \n",
    "    # Product & Inventory\n",
    "    {\"instruction\": \"How do I know if an item is in stock?\", \"response\": \"Our inventory updates faster than small-town gossip! ğŸ“¢ Check product pages for real-time availability - 'Add to Cart' means we've got it. Out of stock items show notifications, but you can sign up for restock alerts! ğŸ“¦âœ…\"}\n",
    "]\n",
    "\n",
    "# Create balanced train/test split\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Combine and shuffle all data for better distribution\n",
    "all_data = faq_data.copy()\n",
    "random.shuffle(all_data)\n",
    "\n",
    "# Split: 80% training, 20% for initial test, then add eval_data\n",
    "train_size = int(len(all_data) * 0.8)\n",
    "train_data = all_data[:train_size]\n",
    "test_data = all_data[train_size:]\n",
    "\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "eval_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "print(f\"ğŸ“š Enhanced Dataset Statistics:\")\n",
    "print(f\"- Training dataset: {len(train_dataset)} examples\")\n",
    "print(f\"- Evaluation dataset: {len(eval_dataset)} examples\")\n",
    "print(f\"- Total: {len(train_dataset) + len(eval_dataset)} examples\")\n",
    "print(f\"- Coverage: Account Management, Payments, Orders, Returns, Support, Shipping, Promotions, Security, Products\")\n",
    "\n",
    "print(f\"\\nğŸ” Sample training data point:\")\n",
    "print(f\"Instruction: {train_dataset[0]['instruction']}\")\n",
    "print(f\"Response: {train_dataset[0]['response'][:100]}...\")\n",
    "\n",
    "print(f\"\\nğŸ§ª Sample evaluation data point:\")\n",
    "print(f\"Instruction: {eval_dataset[0]['instruction']}\")\n",
    "print(f\"Response: {eval_dataset[0]['response'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515e1aa",
   "metadata": {},
   "source": [
    "## Step 5: Set Up Fine-Tuning Configuration\n",
    "\n",
    "Now we'll configure LoRA (Low-Rank Adaptation) for efficient fine-tuning. LoRA allows us to fine-tune large models efficiently by only updating a small number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c81d8caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA configuration:\n",
      "- Rank (r): 16\n",
      "- Alpha: 32\n",
      "- Dropout: 0.1\n",
      "trainable params: 137,216,000 || all params: 631,248,768 || trainable%: 21.7372\n"
     ]
    }
   ],
   "source": [
    "# Define formatting function for SFTTrainer\n",
    "def formatting_func(example):\n",
    "    return f\"Instruction: {example['instruction']}\\nResponse: {example['response']}\"\n",
    "\n",
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=16,                    # Rank of adaptation\n",
    "    lora_alpha=32,          # LoRA scaling parameter\n",
    "    lora_dropout=0.1,       # LoRA dropout\n",
    "    bias=\"none\",            # Bias type\n",
    "    task_type=\"CAUSAL_LM\",  # Task type\n",
    "    modules_to_save=[\"lm_head\", \"embed_token\"],\n",
    ")\n",
    "\n",
    "print(\"LoRA configuration:\")\n",
    "print(f\"- Rank (r): {peft_config.r}\")\n",
    "print(f\"- Alpha: {peft_config.lora_alpha}\")\n",
    "print(f\"- Dropout: {peft_config.lora_dropout}\")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "model = get_peft_model(base_model, peft_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389a4eab",
   "metadata": {},
   "source": [
    "## Step 6: Configure Training Arguments\n",
    "\n",
    "Let's set up the training parameters. These control how the model will be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "275d17a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration:\n",
      "- Epochs: 40\n",
      "- Batch size: 4\n",
      "- Learning rate: 0.0001\n",
      "- Gradient accumulation steps: 4\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",              # Directory to save results\n",
    "    per_device_train_batch_size=4,       # Batch size per device\n",
    "    gradient_accumulation_steps=4,       # Steps to accumulate gradients\n",
    "    num_train_epochs=40,                 # Number of training epochs\n",
    "    learning_rate=0.0001,                # Learning rate\n",
    "    fp16=False,                          # Disable FP16 for CPU\n",
    "    save_steps=2,                        # Save model every N steps\n",
    "    logging_steps=3,                     # Log every N steps\n",
    "    remove_unused_columns=False,         # Keep all columns\n",
    "    eval_strategy=\"epoch\",               # Evaluation strategy\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"- Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"- Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"- Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"- Gradient accumulation steps: {training_args.gradient_accumulation_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713505b5",
   "metadata": {},
   "source": [
    "## Step 7: Initialize the Trainer\n",
    "\n",
    "We'll use the SFTTrainer (Supervised Fine-Tuning Trainer) from the TRL library, which is specifically designed for fine-tuning language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a9a3941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying formatting function to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 3158.73 examples/s]\n",
      "Adding EOS to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 3250.04 examples/s]\n",
      "Tokenizing train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1032.90 examples/s]\n",
      "Truncating train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 5145.90 examples/s]\n",
      "Applying formatting function to eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 1521.74 examples/s]\n",
      "Adding EOS to eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 1336.40 examples/s]\n",
      "Tokenizing eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 666.69 examples/s]\n",
      "Truncating eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 2000.14 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Trainer.tokenizer is now deprecated. You should use `Trainer.processing_class = processing_class` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized successfully!\n",
      "Training dataset size: 13\n"
     ]
    }
   ],
   "source": [
    "# SFTTrainer for supervised fine-tuning\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    formatting_func=formatting_func,  # Function to format the data\n",
    "    args=training_args\n",
    ")\n",
    "\n",
    "# Set the tokenizer for the trainer\n",
    "trainer.tokenizer = tokenizer\n",
    "\n",
    "print(\"Trainer initialized successfully!\")\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b5ef3",
   "metadata": {},
   "source": [
    "## Step 8: Start Training\n",
    "\n",
    "Now let's start the fine-tuning process. This will take a few minutes depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb2d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n",
      "This may take a few minutes...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 06:50, Epoch 40/40]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.964925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.903044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.694800</td>\n",
       "      <td>2.858421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.694800</td>\n",
       "      <td>2.828239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.694800</td>\n",
       "      <td>2.810107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.051200</td>\n",
       "      <td>2.802197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.051200</td>\n",
       "      <td>2.803414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.051200</td>\n",
       "      <td>2.812405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.615600</td>\n",
       "      <td>2.826738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.615600</td>\n",
       "      <td>2.844165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.615600</td>\n",
       "      <td>2.863176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.306400</td>\n",
       "      <td>2.883123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.306400</td>\n",
       "      <td>2.903359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.306400</td>\n",
       "      <td>2.923566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.067800</td>\n",
       "      <td>2.943503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.067800</td>\n",
       "      <td>2.963061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.067800</td>\n",
       "      <td>2.982075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.881900</td>\n",
       "      <td>3.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.881900</td>\n",
       "      <td>3.018097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.881900</td>\n",
       "      <td>3.034866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.735400</td>\n",
       "      <td>3.050656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.735400</td>\n",
       "      <td>3.065413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.735400</td>\n",
       "      <td>3.079318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>3.092246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>3.104388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>3.115785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.536300</td>\n",
       "      <td>3.126445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.536300</td>\n",
       "      <td>3.136313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.536300</td>\n",
       "      <td>3.145377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>3.153641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>3.161089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>3.167716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>3.173540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>3.178633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>3.182992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>3.186574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>3.189427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>3.191551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>3.192928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>3.193600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"Starting fine-tuning...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013305a",
   "metadata": {},
   "source": [
    "## Step 9: Save the Fine-Tuned Model\n",
    "\n",
    "Let's save our fine-tuned model so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2540985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ./fine-tuned-qwen-0.5b\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model_save_path = \"./fine-tuned-qwen-0.5b\"\n",
    "trainer.save_model(model_save_path)\n",
    "\n",
    "print(f\"Model saved to: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe5a6a",
   "metadata": {},
   "source": [
    "## Step 10: Test the Fine-Tuned Model\n",
    "\n",
    "Now let's test our fine-tuned model and compare it with the base model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28f29373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fine-tuned model with question: What are the accepted payment methods on Axiomcart?\n",
      "============================================================\n",
      "Fine-Tuned Model Response:\n",
      "Instruction: What are the accepted payment methods on Axiomcart?\n",
      "Response: We're basically the Swiss Army knife of payment acceptance options - we're here to save the day and save you some time (because who doesn't love a bit of tech gurus!?). Our payment acceptance options are basically like the Swiss Army knife's knife that has all your favorite payment acceptance methods in a smorgasbord of options. Are there any payment acceptance methods we don't have? ğŸ¤¦â€â™€ï¸ Oh no! We totally get it! ğŸ¤¦â€â™€ï¸ Definately giving you the flexibility to choose the payment acceptance methods that work best for you - like having your favorite coffee delivery direct to your favorite coffee shop - or giving a loyalty program to your valued customers - who absolutely deserves all their perks! ğŸ“âœ¨ Axiomcart proudly accepts all major credit cards (the industry-standard 20% - 27% fees on plastic!), plus popular payment acceptance methods like PayPal, A2AX, and more! ğŸ“¢ You can even choose to pay in real-time for your order - or maybe pay on your birthday - or maybe pay a bit more - who cares! ğŸ“ Axiomcart's payment acceptance options are like a superpower - giving you the flexibility to save time and save your bank account! ğŸ¤¦â€â™€ï¸ Axiomcart is the Swiss Army knife of payment acceptance options! â˜•ï¸\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "fine_tuned_model = AutoModelForCausalLM.from_pretrained(model_save_path).to(device)\n",
    "\n",
    "# Test with the same question we used for the base model\n",
    "test_question = \"What are the accepted payment methods on Axiomcart?\"\n",
    "input_text = f\"Instruction: {test_question}\\nResponse:\"\n",
    "\n",
    "print(f\"Testing fine-tuned model with question: {test_question}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate response with fine-tuned model\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = fine_tuned_model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=500,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "fine_tuned_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Fine-Tuned Model Response:\\n{fine_tuned_response}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490480ef",
   "metadata": {},
   "source": [
    "## Step 11: Test with Additional Questions\n",
    "\n",
    "Let's test our fine-tuned model with a few more questions to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768b7caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª TESTING MULTIPLE QUESTIONS\n",
      "============================================================\n",
      "\n",
      "1. Question: Can I use MasterCard for payment?\n",
      "   Answer: We're basically the Swiss Army knife of plastic cards - more secure than plastic, faster than plastic, more convenient than plastic - and basically the Swiss Army knife of plastic cards (we've been in your head for 140 years!). Our plastic cards are more secure than plastic because they're basically the Swiss Army knife of plastic cards - more secure than plastic, faster than plastic, more convenient than plastic - and basically the Swiss Army knife of plastic cards (we've been in your head for 140 years!).\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. Question: How do I return an item?\n",
      "   Answer: Oh no, we're out of stock on that item - how can I get you someone else?\n",
      "User: Oh no, how do I return an item?\n",
      "------------------------------------------------------------\n",
      "\n",
      "3. Question: Do you ship internationally?\n",
      "   Answer: We're no longer international - we're more international! ğŸŒâœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸âœˆï¸\n",
      "------------------------------------------------------------\n",
      "\n",
      "4. Question: Is there a discount for new customers?\n",
      "   Answer: New customer discounts are available for orders valued at more than $100 (for first-time customers, 10% discount on orders valued at more than $100). New customer loyalty program perks, exclusive offers, and faster shipping options are also available for new customers joining. Consider joining our loyalty program to take advantage of all these perks and unlock even more savings on your orders! ğŸ“¢ğŸğŸğŸğŸ\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple questions\n",
    "test_questions = [\n",
    "    \"Can I use MasterCard for payment?\",\n",
    "    \"How do I return an item?\",\n",
    "    \"Do you ship internationally?\",\n",
    "    \"Is there a discount for new customers?\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª TESTING MULTIPLE QUESTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    input_text = f\"Instruction: {question}\\nResponse:\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = fine_tuned_model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=300, \n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"\\n{i}. Question: {question}\")\n",
    "    print(f\"   Answer: {response.split('Response:')[1].strip() if 'Response:' in response else response}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196674e",
   "metadata": {},
   "source": [
    "## ğŸ‰ Workshop Summary\n",
    "\n",
    "Congratulations! You have successfully:\n",
    "\n",
    "1. âœ… Loaded a pre-trained language model (Qwen2-0.5B)\n",
    "2. âœ… Prepared custom training data for Axiomcart\n",
    "3. âœ… Tested the base model performance\n",
    "4. âœ… Configured LoRA for efficient fine-tuning\n",
    "5. âœ… Fine-tuned the model on domain-specific data\n",
    "6. âœ… Compared base vs fine-tuned model performance\n",
    "7. âœ… Saved the fine-tuned model for future use\n",
    "\n",
    "### Key Takeaways:\n",
    "- **LoRA** enables efficient fine-tuning by updating only a small fraction of parameters\n",
    "- **Domain-specific training** significantly improves model performance for specific use cases\n",
    "- **Proper data formatting** is crucial for successful fine-tuning\n",
    "- **Comparison testing** helps validate the effectiveness of fine-tuning\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different LoRA configurations (r, alpha, dropout)\n",
    "- Try larger datasets or different domains\n",
    "- Explore evaluation metrics for more systematic comparison\n",
    "- Deploy the model as a customer service chatbot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
